{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset=load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'][0]\n",
    "#raw_dataset['train'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'].filter(lambda x: len(x['answers']['text'])  !=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where did Super Bowl 50 take place?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['validation'][2]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Santa Clara, California',\n",
       "  \"Levi's Stadium\",\n",
       "  \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
       " 'answer_start': [403, 355, 355]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['validation'][2]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint=\"distilbert-base-cased\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=raw_dataset['train'][1]['context']\n",
    "question=raw_dataset['train'][1][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=tokenizer(question,context)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(question,context,max_length=100,truncation=\"only_second\",stride=50,return_overflowing_tokens=True,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'offset_mapping': [[(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)]], 'overflow_to_sample_mapping': [0, 0, 0, 0]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i in inputs[\"input_ids\"]:\n",
    "    #print(i)\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=[None,0,0,0,0,0,None,1,1,1,1,1,1,1]\n",
    "length=[]\n",
    "e=len(k)-1\n",
    "n=len(k)-1\n",
    "\n",
    "for i in range(n):\n",
    "    if k[i]==1:\n",
    "        sum=0\n",
    "        while(i<=e):\n",
    "            sum=e-i+1\n",
    "            length.append(sum)\n",
    "            e-=1\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer=raw_dataset['train'][1]['answers']\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_start_char=answer[\"answer_start\"][0]\n",
    "ans_end_char=answer[\"answer_start\"][0]+len(answer['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 213\n"
     ]
    }
   ],
   "source": [
    "print(ans_start_char,ans_end_char)\n",
    "seq_ids=inputs.sequence_ids(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_start=seq_ids.index(1)\n",
    "ctx_start\n",
    "ctx_end=len(seq_ids)-seq_ids[::-1].index(1)-1\n",
    "ctx_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=inputs['offset_mapping'][0]\n",
    "start_idx=0\n",
    "end_idx=0\n",
    "if offset[ctx_start][0]>ans_start_char or offset[ctx_end][1]<ans_end_char:\n",
    "    print(\"target is (0,0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 57)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=ctx_start\n",
    "for start_end_char in offset[ctx_start:]:\n",
    "    start,end=start_end_char\n",
    "    if start==ans_start_char:\n",
    "        start_idx=i\n",
    "    if end==ans_end_char:\n",
    "        end_idx=i\n",
    "        break\n",
    "    i+=1\n",
    "start_idx,end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[170, 7335, 5921, 1104, 4028]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids=inputs['input_ids'][0]\n",
    "input_ids[start_idx:end_idx+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a copper statue of Christ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[start_idx:end_idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer_token(ctx_start,ctx_end,ans_start_char,ans_end_char,offset):\n",
    "   \n",
    "    start_idx=0\n",
    "    end_idx=0\n",
    "    if offset[ctx_start][0]>ans_start_char or offset[ctx_end][1]<ans_end_char:\n",
    "        pass\n",
    "    else:\n",
    "        i=ctx_start\n",
    "        for start_end_char in offset[ctx_start:]:\n",
    "            start,end=start_end_char\n",
    "            if start==ans_start_char:\n",
    "                start_idx=i\n",
    "            if end==ans_end_char:\n",
    "                end_idx=i\n",
    "                break\n",
    "            i+=1\n",
    "    return start_idx,end_idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([53, 17, 0, 0], [57, 21, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strt_idxs=[]\n",
    "end_idxs=[]\n",
    "for i,offset in enumerate(inputs['offset_mapping']):\n",
    "    sequence_ids1=inputs.sequence_ids(i)\n",
    "    ctx_start=sequence_ids1.index(1)\n",
    "    ctx_end=len(sequence_ids1)-sequence_ids1[::-1].index(1)-1\n",
    "    ans_start_char=answer[\"answer_start\"][0]\n",
    "    ans_end_char=answer[\"answer_start\"][0]+len(answer['text'][0])\n",
    "    strt_indx,end_indx=find_answer_token(ctx_start,ctx_end,ans_start_char,ans_end_char,offset)\n",
    "    strt_idxs.append(strt_indx)\n",
    "    end_idxs.append(end_indx)\n",
    "strt_idxs,end_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=384\n",
    "stride=128\n",
    "def tokenize_fn_train(batch):\n",
    "    question=[q.strip() for q in batch['question']]\n",
    "    inputs=tokenizer(\n",
    "        question,\n",
    "        batch['context'],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "\n",
    "    )\n",
    "    offset_mapping=inputs.pop(\"offset_mapping\")\n",
    "    orignal_sample_indexes=inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers=batch[\"answers\"]\n",
    "    start_indexes,end_indexes=[], []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx=orignal_sample_indexes[i]\n",
    "        answer=answers[sample_idx]\n",
    "\n",
    "        ans_start_char=answer['answer_start'][0]\n",
    "        ans_end_char=ans_start_char+len(answer['text'][0])\n",
    "        sequence_ids=inputs.sequence_ids(i)\n",
    "        ctx_start=sequence_ids.index(1)\n",
    "        ctx_end=len(sequence_ids)-sequence_ids[::-1].index(1)-1\n",
    "\n",
    "        start_idx,end_idx=find_answer_token(ctx_start,ctx_end,ans_start_char,ans_end_char,offset)\n",
    "        start_indexes.append(start_idx)\n",
    "        end_indexes.append(end_idx)\n",
    "    inputs['start_positions']=start_indexes\n",
    "    inputs['end_positions']=end_indexes\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=raw_dataset['train'].map(tokenize_fn_train,batched=True,remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 88729)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_dataset['train']),len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn_validation(batch):\n",
    "    # Process questions\n",
    "    question = [q.strip() for q in batch['question']]\n",
    "    \n",
    "    # Tokenization\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        batch['context'],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    # Processing Tokenizer Outputs\n",
    "    original_sample_indexes = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    sample_ids = []\n",
    "    for i in range(len(inputs['input_ids'])):\n",
    "        sample_idx = original_sample_indexes[i]\n",
    "        sample_ids.append(batch['id'][sample_idx])\n",
    "        \n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs['offset_mapping'][i]\n",
    "        inputs['offset_mapping'][i] = [x if sequence_ids[j] == 1 else None for j, x in enumerate(offset)]\n",
    "    \n",
    "    # Add sample_ids to inputs\n",
    "    inputs['sample_id'] = sample_ids\n",
    "    \n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10570/10570 [00:19<00:00, 543.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "validation_dataset=raw_dataset['validation'].map(tokenize_fn_validation,batched=True,remove_columns=raw_dataset['validation'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10570, 10822)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_dataset['validation']), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP PC\\AppData\\Local\\Temp\\ipykernel_21620\\1737037727.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric=load_metric('squad')\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric=load_metric('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_validation_dataset=raw_dataset['validation'].select(range(100))\n",
    "trained_checkpoint=\"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer2=AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "old_tokenizer=tokenizer\n",
    "tokenizer=tokenizer2\n",
    "small_validation_processed=small_validation_dataset.map(tokenize_fn_validation,batched=True,remove_columns=raw_dataset['validation'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=old_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'sample_id'],\n",
       "    num_rows: 10822\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'sample_id'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "small_model_inputs=small_validation_processed.remove_columns(['sample_id','offset_mapping'])\n",
    "small_model_inputs.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  5979,  4279,  ...,     0,     0,     0],\n",
       "        [  101,  5979,  4279,  ...,     0,     0,     0],\n",
       "        [  101,  2777,  1225,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1327,  1160,  ...,     0,     0,     0],\n",
       "        [  101,  2627,  3012,  ...,     0,     0,     0],\n",
       "        [  101,  2627, 21188,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "small_model_inputs_gpu={k:small_model_inputs[k].to(device) for k in small_model_inputs.column_names}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  5979,  4279,  ...,     0,     0,     0],\n",
       "         [  101,  5979,  4279,  ...,     0,     0,     0],\n",
       "         [  101,  2777,  1225,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  1327,  1160,  ...,     0,     0,     0],\n",
       "         [  101,  2627,  3012,  ...,     0,     0,     0],\n",
       "         [  101,  2627, 21188,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model_inputs_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model=AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs=trained_model(**small_model_inputs_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ -2.2607,  -5.1783,  -5.2709,  ...,  -9.5243,  -9.5183,  -9.5288],\n",
       "        [ -2.5961,  -5.5482,  -5.5313,  ...,  -9.9598,  -9.9533,  -9.9860],\n",
       "        [ -3.7127,  -7.1848,  -8.5388,  ..., -11.6557, -11.6571, -11.6505],\n",
       "        ...,\n",
       "        [ -2.0260,  -4.4167,  -4.4980,  ...,  -8.1479,  -8.1530,  -8.1760],\n",
       "        [ -4.1553,  -5.8304,  -7.1643,  ..., -10.5255, -10.5251, -10.4890],\n",
       "        [ -3.2000,  -5.8162,  -6.7249,  ...,  -9.4935,  -9.5038,  -9.4871]]), end_logits=tensor([[ -0.7353,  -4.9236,  -5.1048,  ...,  -8.8734,  -8.8916,  -8.8550],\n",
       "        [ -1.3056,  -5.3870,  -5.4945,  ...,  -9.4895,  -9.5039,  -9.4959],\n",
       "        [ -2.7649,  -7.2201,  -9.0916,  ..., -11.3106, -11.3414, -11.2702],\n",
       "        ...,\n",
       "        [ -0.0768,  -4.8210,  -4.4374,  ...,  -8.0483,  -8.0502,  -7.9903],\n",
       "        [ -2.7347,  -5.3650,  -7.2549,  ..., -10.0498, -10.0661,  -9.9886],\n",
       "        [ -1.0991,  -4.2569,  -6.1267,  ...,  -8.6882,  -8.6889,  -8.6272]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits=outputs.start_logits.cpu().numpy()\n",
    "end_logits=outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56be4db0acb8001400a502ec\n",
      "1 56be4db0acb8001400a502ed\n",
      "2 56be4db0acb8001400a502ee\n",
      "3 56be4db0acb8001400a502ef\n",
      "4 56be4db0acb8001400a502f0\n",
      "5 56be8e613aeaaa14008c90d1\n",
      "6 56be8e613aeaaa14008c90d2\n",
      "7 56be8e613aeaaa14008c90d3\n",
      "8 56bea9923aeaaa14008c91b9\n",
      "9 56bea9923aeaaa14008c91ba\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(small_validation_processed['sample_id'][:10]):\n",
    "    print(i,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id2idxs={}\n",
    "for i,id_ in enumerate(small_validation_processed['sample_id']):\n",
    "    if id_ not in sample_id2idxs:\n",
    "        sample_id2idxs[id_]=[i]\n",
    "    else:\n",
    "        sample_id2idxs[id_].append(i)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('56be4db0acb8001400a502ec', [0])\n",
      "('56be4db0acb8001400a502ed', [1])\n",
      "('56be4db0acb8001400a502ee', [2])\n",
      "('56be4db0acb8001400a502ef', [3])\n",
      "('56be4db0acb8001400a502f0', [4])\n",
      "('56be8e613aeaaa14008c90d1', [5])\n",
      "('56be8e613aeaaa14008c90d2', [6])\n",
      "('56be8e613aeaaa14008c90d3', [7])\n",
      "('56bea9923aeaaa14008c91b9', [8])\n",
      "('56bea9923aeaaa14008c91ba', [9])\n",
      "('56bea9923aeaaa14008c91bb', [10])\n",
      "('56beace93aeaaa14008c91df', [11])\n",
      "('56beace93aeaaa14008c91e0', [12])\n",
      "('56beace93aeaaa14008c91e1', [13])\n",
      "('56beace93aeaaa14008c91e2', [14])\n",
      "('56beace93aeaaa14008c91e3', [15])\n",
      "('56bf10f43aeaaa14008c94fd', [16])\n",
      "('56bf10f43aeaaa14008c94fe', [17])\n",
      "('56bf10f43aeaaa14008c94ff', [18])\n",
      "('56bf10f43aeaaa14008c9500', [19])\n",
      "('56bf10f43aeaaa14008c9501', [20])\n",
      "('56d20362e7d4791d009025e8', [21])\n",
      "('56d20362e7d4791d009025e9', [22])\n",
      "('56d20362e7d4791d009025ea', [23])\n",
      "('56d20362e7d4791d009025eb', [24])\n",
      "('56d600e31c85041400946eae', [25])\n",
      "('56d600e31c85041400946eb0', [26])\n",
      "('56d600e31c85041400946eb1', [27])\n",
      "('56d9895ddc89441400fdb50e', [28])\n",
      "('56d9895ddc89441400fdb510', [29])\n",
      "('56be4e1facb8001400a502f6', [30])\n",
      "('56be4e1facb8001400a502f9', [31])\n",
      "('56be4e1facb8001400a502fa', [32])\n",
      "('56beaa4a3aeaaa14008c91c2', [33])\n",
      "('56beaa4a3aeaaa14008c91c3', [34])\n",
      "('56bead5a3aeaaa14008c91e9', [35])\n",
      "('56bead5a3aeaaa14008c91ea', [36])\n",
      "('56bead5a3aeaaa14008c91eb', [37])\n",
      "('56bead5a3aeaaa14008c91ec', [38])\n",
      "('56bead5a3aeaaa14008c91ed', [39])\n",
      "('56bf159b3aeaaa14008c9507', [40])\n",
      "('56bf159b3aeaaa14008c9508', [41])\n",
      "('56bf159b3aeaaa14008c9509', [42])\n",
      "('56bf159b3aeaaa14008c950a', [43])\n",
      "('56bf159b3aeaaa14008c950b', [44])\n",
      "('56d2045de7d4791d009025f3', [45])\n",
      "('56d2045de7d4791d009025f4', [46])\n",
      "('56d2045de7d4791d009025f5', [47])\n",
      "('56d2045de7d4791d009025f6', [48])\n",
      "('56d6017d1c85041400946ebe', [49])\n",
      "('56d6017d1c85041400946ec1', [50])\n",
      "('56d6017d1c85041400946ec2', [51])\n",
      "('56d98a59dc89441400fdb52a', [52])\n",
      "('56d98a59dc89441400fdb52b', [53])\n",
      "('56d98a59dc89441400fdb52e', [54])\n",
      "('56be4eafacb8001400a50302', [55])\n",
      "('56be4eafacb8001400a50303', [56])\n",
      "('56be4eafacb8001400a50304', [57])\n",
      "('56beab833aeaaa14008c91d2', [58])\n",
      "('56beab833aeaaa14008c91d3', [59])\n",
      "('56beab833aeaaa14008c91d4', [60])\n",
      "('56beae423aeaaa14008c91f4', [61])\n",
      "('56beae423aeaaa14008c91f5', [62])\n",
      "('56beae423aeaaa14008c91f6', [63])\n",
      "('56beae423aeaaa14008c91f7', [64])\n",
      "('56bf17653aeaaa14008c9511', [65])\n",
      "('56bf17653aeaaa14008c9513', [66])\n",
      "('56bf17653aeaaa14008c9514', [67])\n",
      "('56bf17653aeaaa14008c9515', [68])\n",
      "('56d204ade7d4791d00902603', [69])\n",
      "('56d204ade7d4791d00902604', [70])\n",
      "('56d601e41c85041400946ece', [71])\n",
      "('56d601e41c85041400946ecf', [72])\n",
      "('56d601e41c85041400946ed0', [73])\n",
      "('56d601e41c85041400946ed1', [74])\n",
      "('56d601e41c85041400946ed2', [75])\n",
      "('56d98b33dc89441400fdb53b', [76])\n",
      "('56d98b33dc89441400fdb53c', [77])\n",
      "('56d98b33dc89441400fdb53d', [78])\n",
      "('56d98b33dc89441400fdb53e', [79])\n",
      "('56be5333acb8001400a5030a', [80])\n",
      "('56be5333acb8001400a5030b', [81])\n",
      "('56be5333acb8001400a5030c', [82])\n",
      "('56be5333acb8001400a5030d', [83])\n",
      "('56be5333acb8001400a5030e', [84])\n",
      "('56beaf5e3aeaaa14008c91fd', [85])\n",
      "('56beaf5e3aeaaa14008c91fe', [86])\n",
      "('56beaf5e3aeaaa14008c91ff', [87])\n",
      "('56beaf5e3aeaaa14008c9200', [88])\n",
      "('56beaf5e3aeaaa14008c9201', [89])\n",
      "('56bf1ae93aeaaa14008c951b', [90])\n",
      "('56bf1ae93aeaaa14008c951c', [91])\n",
      "('56bf1ae93aeaaa14008c951e', [92])\n",
      "('56bf1ae93aeaaa14008c951f', [93])\n",
      "('56d2051ce7d4791d00902608', [94])\n",
      "('56d2051ce7d4791d00902609', [95])\n",
      "('56d2051ce7d4791d0090260a', [96])\n",
      "('56d2051ce7d4791d0090260b', [97])\n",
      "('56d602631c85041400946ed8', [98])\n",
      "('56d602631c85041400946eda', [99])\n"
     ]
    }
   ],
   "source": [
    "for i in sample_id2idxs.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 384), (100, 384))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits.shape , end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_largest=20\n",
    "max_answer_length=30\n",
    "predicted_answers=[]\n",
    "for sample in small_validation_dataset:\n",
    "    sample_id=sample['id']\n",
    "    context=sample['context']\n",
    "    best_score=float(\"-inf\")\n",
    "    best_anwer=None\n",
    "    for idx in sample_id2idxs[sample_id]:\n",
    "        start_logit=start_logits[idx]\n",
    "        end_logit=end_logits[idx]\n",
    "        offsets=small_validation_processed[idx]['offset_mapping']\n",
    "        start_indices=(-start_logit).argsort()\n",
    "        end_indices=(-end_logit).argsort()\n",
    "\n",
    "        for start_idx in start_indices[:n_largest]:\n",
    "            for end_idx in end_indices[:n_largest]:\n",
    "                if offsets[start_idx] is None or offsets[end_idx] is None:\n",
    "                    continue\n",
    "                if end_idx<start_idx:\n",
    "                    continue\n",
    "                if end_idx-start_idx+1>max_answer_length:\n",
    "                    continue\n",
    "                score=start_logit[start_idx]+end_logit[end_idx]\n",
    "                if score>best_score:\n",
    "                    best_score=score\n",
    "                    first_ch=offsets[start_idx][0]\n",
    "                    last_ch=offsets[end_idx][1]\n",
    "                    best_answer=context[first_ch:last_ch]\n",
    "    predicted_answers.append({'id':sample_id,'prediction_text':best_answer})\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'},\n",
       " {'id': '56be4db0acb8001400a502ed', 'prediction_text': 'Carolina Panthers'},\n",
       " {'id': '56be4db0acb8001400a502ee',\n",
       "  'prediction_text': \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California\"},\n",
       " {'id': '56be4db0acb8001400a502ef', 'prediction_text': 'Carolina Panthers'},\n",
       " {'id': '56be4db0acb8001400a502f0', 'prediction_text': 'gold'},\n",
       " {'id': '56be8e613aeaaa14008c90d1', 'prediction_text': 'golden anniversary'},\n",
       " {'id': '56be8e613aeaaa14008c90d2', 'prediction_text': 'February 7, 2016'},\n",
       " {'id': '56be8e613aeaaa14008c90d3',\n",
       "  'prediction_text': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference'},\n",
       " {'id': '56bea9923aeaaa14008c91b9', 'prediction_text': 'golden anniversary'},\n",
       " {'id': '56bea9923aeaaa14008c91ba',\n",
       "  'prediction_text': 'American Football Conference'},\n",
       " {'id': '56bea9923aeaaa14008c91bb', 'prediction_text': 'February 7, 2016'},\n",
       " {'id': '56beace93aeaaa14008c91df', 'prediction_text': 'Denver Broncos'},\n",
       " {'id': '56beace93aeaaa14008c91e0', 'prediction_text': \"Levi's Stadium\"},\n",
       " {'id': '56beace93aeaaa14008c91e1',\n",
       "  'prediction_text': 'Santa Clara, California'},\n",
       " {'id': '56beace93aeaaa14008c91e2', 'prediction_text': 'Super Bowl L'},\n",
       " {'id': '56beace93aeaaa14008c91e3', 'prediction_text': '2015'},\n",
       " {'id': '56bf10f43aeaaa14008c94fd', 'prediction_text': '2016'},\n",
       " {'id': '56bf10f43aeaaa14008c94fe',\n",
       "  'prediction_text': 'Santa Clara, California'},\n",
       " {'id': '56bf10f43aeaaa14008c94ff', 'prediction_text': \"Levi's Stadium\"},\n",
       " {'id': '56bf10f43aeaaa14008c9500', 'prediction_text': '24–10'},\n",
       " {'id': '56bf10f43aeaaa14008c9501', 'prediction_text': 'February 7, 2016'},\n",
       " {'id': '56d20362e7d4791d009025e8', 'prediction_text': '2015'},\n",
       " {'id': '56d20362e7d4791d009025e9', 'prediction_text': 'Denver Broncos'},\n",
       " {'id': '56d20362e7d4791d009025ea', 'prediction_text': 'Carolina Panthers'},\n",
       " {'id': '56d20362e7d4791d009025eb', 'prediction_text': 'Denver Broncos'},\n",
       " {'id': '56d600e31c85041400946eae', 'prediction_text': '2015'},\n",
       " {'id': '56d600e31c85041400946eb0', 'prediction_text': 'Carolina Panthers'},\n",
       " {'id': '56d600e31c85041400946eb1', 'prediction_text': \"Levi's Stadium\"},\n",
       " {'id': '56d9895ddc89441400fdb50e', 'prediction_text': 'Super Bowl 50'},\n",
       " {'id': '56d9895ddc89441400fdb510', 'prediction_text': 'Denver Broncos'},\n",
       " {'id': '56be4e1facb8001400a502f6', 'prediction_text': 'Cam Newton'},\n",
       " {'id': '56be4e1facb8001400a502f9', 'prediction_text': 'eight'},\n",
       " {'id': '56be4e1facb8001400a502fa', 'prediction_text': '1995'},\n",
       " {'id': '56beaa4a3aeaaa14008c91c2', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56beaa4a3aeaaa14008c91c3', 'prediction_text': 'New England Patriots'},\n",
       " {'id': '56bead5a3aeaaa14008c91e9', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56bead5a3aeaaa14008c91ea', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56bead5a3aeaaa14008c91eb', 'prediction_text': 'New England Patriots'},\n",
       " {'id': '56bead5a3aeaaa14008c91ec', 'prediction_text': 'four'},\n",
       " {'id': '56bead5a3aeaaa14008c91ed', 'prediction_text': 'Cam Newton'},\n",
       " {'id': '56bf159b3aeaaa14008c9507', 'prediction_text': '15–1'},\n",
       " {'id': '56bf159b3aeaaa14008c9508', 'prediction_text': 'Cam Newton'},\n",
       " {'id': '56bf159b3aeaaa14008c9509', 'prediction_text': '15–1 record'},\n",
       " {'id': '56bf159b3aeaaa14008c950a', 'prediction_text': 'four'},\n",
       " {'id': '56bf159b3aeaaa14008c950b', 'prediction_text': 'New England Patriots'},\n",
       " {'id': '56d2045de7d4791d009025f3', 'prediction_text': 'Cam Newton'},\n",
       " {'id': '56d2045de7d4791d009025f4', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56d2045de7d4791d009025f5', 'prediction_text': 'eight'},\n",
       " {'id': '56d2045de7d4791d009025f6', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56d6017d1c85041400946ebe', 'prediction_text': 'Cam Newton'},\n",
       " {'id': '56d6017d1c85041400946ec1', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56d6017d1c85041400946ec2', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56d98a59dc89441400fdb52a', 'prediction_text': 'Cam Newton'},\n",
       " {'id': '56d98a59dc89441400fdb52b', 'prediction_text': 'Arizona Cardinals'},\n",
       " {'id': '56d98a59dc89441400fdb52e', 'prediction_text': '1995'},\n",
       " {'id': '56be4eafacb8001400a50302', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56be4eafacb8001400a50303', 'prediction_text': 'two'},\n",
       " {'id': '56be4eafacb8001400a50304', 'prediction_text': 'Broncos'},\n",
       " {'id': '56beab833aeaaa14008c91d2', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56beab833aeaaa14008c91d3', 'prediction_text': 'five'},\n",
       " {'id': '56beab833aeaaa14008c91d4', 'prediction_text': 'Newton'},\n",
       " {'id': '56beae423aeaaa14008c91f4', 'prediction_text': 'seven'},\n",
       " {'id': '56beae423aeaaa14008c91f5', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56beae423aeaaa14008c91f6', 'prediction_text': 'three'},\n",
       " {'id': '56beae423aeaaa14008c91f7', 'prediction_text': 'two'},\n",
       " {'id': '56bf17653aeaaa14008c9511', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56bf17653aeaaa14008c9513', 'prediction_text': 'linebacker'},\n",
       " {'id': '56bf17653aeaaa14008c9514', 'prediction_text': 'five'},\n",
       " {'id': '56bf17653aeaaa14008c9515', 'prediction_text': 'two'},\n",
       " {'id': '56d204ade7d4791d00902603', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56d204ade7d4791d00902604', 'prediction_text': 'five'},\n",
       " {'id': '56d601e41c85041400946ece', 'prediction_text': 'seven'},\n",
       " {'id': '56d601e41c85041400946ecf', 'prediction_text': 'three'},\n",
       " {'id': '56d601e41c85041400946ed0', 'prediction_text': 'a fumble'},\n",
       " {'id': '56d601e41c85041400946ed1', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56d601e41c85041400946ed2', 'prediction_text': 'linebacker'},\n",
       " {'id': '56d98b33dc89441400fdb53b', 'prediction_text': 'seven'},\n",
       " {'id': '56d98b33dc89441400fdb53c', 'prediction_text': 'three'},\n",
       " {'id': '56d98b33dc89441400fdb53d', 'prediction_text': 'Von Miller'},\n",
       " {'id': '56d98b33dc89441400fdb53e', 'prediction_text': 'five'},\n",
       " {'id': '56be5333acb8001400a5030a', 'prediction_text': 'CBS'},\n",
       " {'id': '56be5333acb8001400a5030b', 'prediction_text': '$5 million'},\n",
       " {'id': '56be5333acb8001400a5030c', 'prediction_text': 'Coldplay'},\n",
       " {'id': '56be5333acb8001400a5030d',\n",
       "  'prediction_text': 'Beyoncé and Bruno Mars'},\n",
       " {'id': '56be5333acb8001400a5030e', 'prediction_text': 'Super Bowl 50'},\n",
       " {'id': '56beaf5e3aeaaa14008c91fd', 'prediction_text': 'CBS'},\n",
       " {'id': '56beaf5e3aeaaa14008c91fe', 'prediction_text': '$5 million'},\n",
       " {'id': '56beaf5e3aeaaa14008c91ff',\n",
       "  'prediction_text': 'Beyoncé and Bruno Mars'},\n",
       " {'id': '56beaf5e3aeaaa14008c9200',\n",
       "  'prediction_text': 'Beyoncé and Bruno Mars'},\n",
       " {'id': '56beaf5e3aeaaa14008c9201',\n",
       "  'prediction_text': 'Beyoncé and Bruno Mars'},\n",
       " {'id': '56bf1ae93aeaaa14008c951b', 'prediction_text': 'CBS'},\n",
       " {'id': '56bf1ae93aeaaa14008c951c', 'prediction_text': '$5 million'},\n",
       " {'id': '56bf1ae93aeaaa14008c951e',\n",
       "  'prediction_text': 'Beyoncé and Bruno Mars'},\n",
       " {'id': '56bf1ae93aeaaa14008c951f', 'prediction_text': 'third'},\n",
       " {'id': '56d2051ce7d4791d00902608', 'prediction_text': 'CBS'},\n",
       " {'id': '56d2051ce7d4791d00902609', 'prediction_text': '$5 million'},\n",
       " {'id': '56d2051ce7d4791d0090260a', 'prediction_text': 'Coldplay'},\n",
       " {'id': '56d2051ce7d4791d0090260b',\n",
       "  'prediction_text': 'Beyoncé and Bruno Mars'},\n",
       " {'id': '56d602631c85041400946ed8', 'prediction_text': 'CBS'},\n",
       " {'id': '56d602631c85041400946eda',\n",
       "  'prediction_text': 'Coldplay with special guest performers Beyoncé and Bruno Mars'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_answers=[{\"id\":x['id'],'answers':x['answers']} for x in small_validation_dataset]\n",
    "metric.compute(predictions=predicted_answers,references=true_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "def compute_metrics(start_logits,end_logits,processed_dataset,orig_dataset):\n",
    "    sample_id2idxs={}\n",
    "    for i,id_ in enumerate(processed_dataset['sample_id']):\n",
    "        if id_ not in sample_id2idxs:\n",
    "            sample_id2idxs[id_]=[i]\n",
    "        else:\n",
    "            sample_id2idxs[id_].append(i)\n",
    "    predicted_answers=[]\n",
    "    for sample in tqdm(orig_dataset):\n",
    "        sample_id=sample['id']\n",
    "        context=sample['context']\n",
    "        best_score=float(\"-inf\")\n",
    "        best_answer=None\n",
    "        for idx in sample_id2idxs[sample_id]:\n",
    "            start_logit=start_logits[idx]\n",
    "            end_logit=end_logits[idx]\n",
    "            offsets=processed_dataset[idx]['offset_mapping']\n",
    "            start_indices=(-start_logit).argsort()\n",
    "            end_indices=(-end_logit).argsort()\n",
    "            for start_idx in start_indices[:n_largest]:\n",
    "                for end_idx in end_indices[:n_largest]:\n",
    "                    if offsets[start_idx] is None or offsets[end_idx] is None:\n",
    "                        continue\n",
    "                    if end_idx<start_idx:\n",
    "                        continue\n",
    "                    if end_idx-start_idx+1>max_answer_length:\n",
    "                        continue\n",
    "                    score=start_logit[start_idx]+end_logit[end_idx]\n",
    "                    if score>best_score:\n",
    "                        best_score=score\n",
    "                        first_ch=offsets[start_idx][0]\n",
    "                        last_ch=offsets[end_idx][1]\n",
    "                        best_answer=context[first_ch:last_ch]\n",
    "        predicted_answers.append({'id':sample_id,'prediction_text':best_answer})\n",
    "    true_answers=[{\"id\":x['id'],'answers':x['answers']} for x in orig_dataset]\n",
    "    return metric.compute(predictions=predicted_answers,references=true_answers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 133.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(start_logits,end_logits,small_validation_processed,small_validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "args=TrainingArguments(\"finetuned_squad\",evaluation_strategy='no',save_strategy='epoch',learning_rate=2e-5,num_train_epochs=3,weight_decay=0.01)\n",
    "trainer=Trainer(model=model,args=args,train_dataset=train_dataset,eval_dataset=validation_dataset,tokenizer=tokenizer)\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
